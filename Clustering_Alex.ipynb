{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13048a44-7cdf-497d-a96b-f418645a73b5",
   "metadata": {},
   "source": [
    "### HYO HRSTEM images anlaysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c8e00c-4a64-4db5-b12f-845abf0bdf92",
   "metadata": {},
   "source": [
    "The following are imports and functions to plot or process some of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d20cdc0c-c8c8-4e3e-bf92-cd79952cb99c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T22:05:14.608420400Z",
     "start_time": "2024-11-20T22:05:14.586421300Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy._lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# from rsciio import digitalmicrograph  # Not available in standard installation\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvpcffit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m select_files, save_vpcfs, load_vpcfs, xy_to_rt, rt_to_xy, create_zone_axes\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvpcffit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvpcffit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_vpcf_from_cif, get_vpcf_from_cif2, align_point_clouds \n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvpcffit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvpcffit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m supercell_axis_cif, get_image_from_atoms, create_vpcfs_images\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alexg\\Downloads\\Conventional-STEM-Clustering\\vpcffit\\utils.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrayLike\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspatial\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConvexHull\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcontextlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m contextmanager\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alexg\\Downloads\\Conventional-STEM-Clustering\\.venv\\Lib\\site-packages\\scipy\\__init__.py:76\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _distributor_init\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m _distributor_init\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pep440\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# In maintenance branch, change to np_maxversion N+3 if numpy is at N\u001b[39;00m\n\u001b[32m     78\u001b[39m np_minversion = \u001b[33m'\u001b[39m\u001b[33m1.26.4\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scipy._lib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "# from rsciio import digitalmicrograph  # Not available in standard installation\n",
    "import matplotlib.pyplot as plt\n",
    "from vpcffit.utils import select_files, save_vpcfs, load_vpcfs, xy_to_rt, rt_to_xy, create_zone_axes\n",
    "from vpcffit.vpcffit import get_vpcf_from_cif, get_vpcf_from_cif2, align_point_clouds \n",
    "from vpcffit.vpcffit import supercell_axis_cif, get_image_from_atoms, create_vpcfs_images\n",
    "from vpcffit.vpcffit import extract_peak_coords\n",
    "from ase.visualize import view\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from ipywidgets import interact, HBox, VBox\n",
    "from vpcffit.vpcffit import align_point_clouds, near_neighbor_distance, crop_at_position\n",
    "from scipy.ndimage import rotate\n",
    "from joblib import Parallel, delayed\n",
    "import copy\n",
    "import atomap.api as am\n",
    "import hyperspy.api as hs\n",
    "from scipy.optimize import minimize\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "#A function to create an interactive plot to compare two vPCFs\n",
    "def compare_vpcfs(vpcf1, vpcf2, fix_zone = False, limit = 500, names = [\"vpcf1\",\"vpcf2\"], colors = ['red', 'blue'], markersize = [6,4]):\n",
    "    \n",
    "    vPCF = go.Scatterpolar(theta=[0], r=[0], mode='markers', name='vPCF1',\n",
    "                            marker = dict(color=colors[0], size=markersize[0]))\n",
    "    vPCF2 = go.Scatterpolar(theta=[0], r=[0], mode='markers', name='vPCF2',\n",
    "                                marker = dict(color=colors[1], size=markersize[1]))\n",
    "    \n",
    "    fig = go.FigureWidget(data=[vPCF, vPCF2])\n",
    "    \n",
    "    # Create a function to update the plot\n",
    "    def update_plot(phase, phase2):\n",
    "        if fix_zone:\n",
    "            vpc1 = vpcf1[phase][(np.sqrt(vpcf1[phase][:,0]**2+vpcf1[phase][:,1]**2)<limit)]\n",
    "            vpc2 = vpcf2[phase][(np.sqrt(vpcf2[phase][:,0]**2+vpcf2[phase][:,1]**2)<limit)]\n",
    "            aligned = align_point_clouds(vpc1, vpc2)\n",
    "            fig.data[0].name = names[0]\n",
    "            fig.data[1].name = names[1]\n",
    "        else:\n",
    "            vpc1 = vpcf1[phase][(np.sqrt(vpcf1[phase][:,0]**2+vpcf1[phase][:,1]**2)<limit)]\n",
    "            vpc2 = vpcf2[phase2][(np.sqrt(vpcf2[phase2][:,0]**2+vpcf2[phase2][:,1]**2)<limit)]\n",
    "            aligned = align_point_clouds(vpc1, vpc2)\n",
    "            fig.data[0].name = phase\n",
    "            fig.data[1].name = phase2\n",
    "        rt_data = xy_to_rt(aligned[1]) # align_point_clouds returns the reference vpcf in the second position of the list\n",
    "        rt_data2 = xy_to_rt(aligned[0]) # align_point_clouds returns the target vpcf after rotation in the first position of the list\n",
    "        fig.data[0].update(r=rt_data[:, 0], theta=rt_data[:, 1] * 180 / np.pi)\n",
    "        fig.data[1].update(r=rt_data2[:, 0], theta=rt_data2[:, 1] * 180 / np.pi)\n",
    "        fig.show()\n",
    "    # Create a dropdown for selecting the plot type\n",
    "    plot_dropdown = widgets.Dropdown(\n",
    "        options=list(vpcf1.keys()),\n",
    "        description=\"First vPCF:\"\n",
    "    )\n",
    "\n",
    "    plot_dropdown_2 = widgets.Dropdown(\n",
    "        options=list(vpcf2.keys()),\n",
    "        description=\"Second vPCF:\",\n",
    "        disabled=fix_zone\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        #title=\"Select the vPCF to plot\",\n",
    "        width=800,  # Set the width to 800 pixels\n",
    "        height=600,  # Set the height to 600 pixels\n",
    "        polar=dict(radialaxis=dict(range=[0, limit],\n",
    "                  showline=False,  # Show the radial axis lines\n",
    "                  linewidth=1.5,    # Set the width of the radial axis lines\n",
    "                  linecolor=\"black\",  # Set the color of the radial axis lines\n",
    "                  showticklabels=False,\n",
    "                  ),\n",
    "                  angularaxis=dict(\n",
    "                          showline=True,  # Show the radial axis lines\n",
    "                          linewidth=1.5,    # Set the width of the radial axis lines\n",
    "                          linecolor=\"black\"  # Set the color of the radial axis lines\n",
    "                          ),\n",
    "                  bgcolor=\"rgba(0,0,0,0)\",# Transparent background for polar plot area\n",
    "                          ),\n",
    "        legend=dict(orientation=\"h\",\n",
    "                   xanchor=\"center\",\n",
    "                   x=0.5,                       \n",
    "           ),\n",
    "    )\n",
    "\n",
    "    [interact(update_plot, phase=plot_dropdown, phase2=plot_dropdown_2)]\n",
    "    \n",
    "def compare_exp_plot(match_DB, target, keys, sigma_threshold = 3, save = False, file= None, model = 'Powell', mark_size=5):\n",
    "    tree_values= match_DB[0]\n",
    "    rotation = match_DB[1]\n",
    "    bs = match_DB[2]\n",
    "    sigma = match_DB[3]\n",
    "    best_match_itree = np.argmin(tree_values)\n",
    "    best_scale_match = bs[best_match_itree]\n",
    "    best_rotation =  rotation[best_match_itree]\n",
    "    best_match_pc = np.array(library_pcs[best_match_itree]) \n",
    "    \n",
    "    sorted_tree_values, sorted_keys, sorted_sigma, sorted_bs, sorted_rotation = zip(*sorted(zip(tree_values, keys, sigma, bs, rotation)))\n",
    "    \n",
    "    #compare the arrays to see differences\n",
    "    differences = np.abs(np.array(sorted_tree_values) - sorted_tree_values[0])\n",
    "    combined_sigma = np.sqrt((sigma_threshold*np.array(sigma))**2 + (sigma_threshold*np.array(sorted_sigma[0]))**2)\n",
    "    within_sigma = differences <= combined_sigma\n",
    "    matches = np.where(within_sigma)[0]\n",
    "    colorbar = ['#1f77b4'] * len(keys)\n",
    "    best_match_tree = []\n",
    "    for index in matches:\n",
    "        colorbar[index] = 'pink'\n",
    "        best_match_tree.append(sorted_keys[index])\n",
    "\n",
    "    #plot\n",
    "    bar1 = go.Bar(\n",
    "        x=sorted_keys,\n",
    "        y=sorted_tree_values,\n",
    "        marker_color = colorbar,\n",
    "        text=[f\"{num:.2f}   \" for num in sorted_bs],         # Text on top of each bar\n",
    "        textposition='outside',  # Position text above bars\n",
    "        textangle=90,\n",
    "        error_y = dict(\n",
    "            type='data',           # Type of error, can also be 'percent' or 'constant'\n",
    "            array=sigma,    # Error values for each bar\n",
    "            #visible=True           # Display the error bars\n",
    "        ),\n",
    "        hovertemplate=(\n",
    "                    '<b>Category:</b> %{x}<br>'  # Displays the x value (Category)\n",
    "                    '<b>Value:</b> %{y}<br>'     # Displays the y value\n",
    "                    '<b>scale:</b> %{text}'  # Displays the error value\n",
    "                    '<extra></extra>'  # Removes the default trace name\n",
    "                )\n",
    "        )\n",
    "    \n",
    "    # vPCF initially showing Experimental data\n",
    "    vPCF1 = go.Scatterpolar(theta=np.mod(xy_to_rt(target)[:,1] + best_rotation,2*np.pi)*180/np.pi,\n",
    "                            r=xy_to_rt(target)[:,0]*best_scale_match,\n",
    "                            mode='markers', \n",
    "                            name='Experimental<br>vPCFs',\n",
    "                            marker=dict(color='blue', size=mark_size))\n",
    "    \n",
    "    # vPCF initially showing best match\n",
    "    vPCF2 = go.Scatterpolar(theta=xy_to_rt(best_match_pc)[:,1]*180/np.pi,\n",
    "                            r=xy_to_rt(best_match_pc)[:,0],\n",
    "                            mode='markers',\n",
    "                            name=\"Best Matches<br>\" + str(best_match_tree),\n",
    "                            marker = dict(color='red', size=mark_size-int(mark_size/2)))\n",
    "    \n",
    "    fig = go.FigureWidget(data=[bar1])\n",
    "    #fig1 = go.FigureWidget(data=[virtual])\n",
    "    #fig2 = go.FigureWidget(data=[experiment])\n",
    "    fig3 = go.FigureWidget(data=[vPCF1, vPCF2])\n",
    "\n",
    "    \n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        height=400, width=800,\n",
    "        showlegend=False,\n",
    "        title = \"Average Near Neighbor Distance\",\n",
    "        xaxis=dict(tickangle=90),  # Rotate x-axis labels\n",
    "        xaxis2=dict(tickangle=90),\n",
    "        hovermode=\"closest\",\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"left\",\n",
    "            x=0\n",
    "        )\n",
    "    )\n",
    "   \n",
    "    fig3.update_layout(height=400, width=400,\n",
    "                       legend=dict(\n",
    "                                    orientation=\"h\",\n",
    "                                    yanchor=\"bottom\",\n",
    "                                    y=1.02,\n",
    "                                    xanchor=\"left\",\n",
    "                                    x=0\n",
    "                                    ),\n",
    "                        polar=dict(radialaxis=dict(range=[0, limit],\n",
    "                              showline=False,  # Show the radial axis lines\n",
    "                              linewidth=1.5,    # Set the width of the radial axis lines\n",
    "                              linecolor=\"black\",  # Set the color of the radial axis lines\n",
    "                              showticklabels=False,\n",
    "                              showgrid=True,  # Turn on the radial grid\n",
    "                              gridcolor=\"grey\",  # Color of the radial grid\n",
    "                              griddash=\"dot\",  # Style of the radial grid (solid, dot, dash)\n",
    "                              gridwidth=1  # Thickness of the grid line\n",
    "                              ),\n",
    "                              angularaxis=dict(\n",
    "                                      showline=True,  # Show the radial axis lines\n",
    "                                      linewidth=1.5,    # Set the width of the radial axis lines\n",
    "                                      linecolor=\"black\"  # Set the color of the radial axis lines\n",
    "                                      ),\n",
    "                              bgcolor=\"rgba(0,0,0,0)\",# Transparent background for polar plot area\n",
    "                                      ),\n",
    "    )\n",
    "    \n",
    "    def onclick_fn(trace, points, state):\n",
    "        inds = np.array(points.point_inds)\n",
    "        if inds.size:\n",
    "            vPCFs2.name = str(points.xs)\n",
    "            index = keys.index(vPCFs2.name[2:-2])\n",
    "            vPCFs1.r = xy_to_rt(target)[:,0]*bs[index]\n",
    "            vPCFs1.theta = np.mod(xy_to_rt(target)[:,1]+rotation[index],2*np.pi)*180/np.pi\n",
    "            vPCFs2.r = xy_to_rt(library_pcs[index])[:,0]\n",
    "            vPCFs2.theta = xy_to_rt(library_pcs[index])[:,1]*180/np.pi\n",
    "            rotated_image, virtual, virtual_size, coord_DB = images_com (rotation[index], index)\n",
    "            vir.z = - virtual\n",
    "            exp.z = - rotated_image\n",
    "            for i, key in enumerate(coord_DB):\n",
    "                fig1.data[i+1].x = coord_DB[key][:,1]\n",
    "                fig1.data[i+1].y = coord_DB[key][:,0]\n",
    "    \n",
    "    bar1 = fig.data[0]\n",
    "    #vir = fig1.data[0]\n",
    "    #exp = fig2.data[0]\n",
    "    vPCFs1 = fig3.data[0]\n",
    "    vPCFs2 = fig3.data[1]\n",
    "    bar1.on_click(onclick_fn)\n",
    "    \n",
    "    # ipywidgets\n",
    "    from ipywidgets import HBox, VBox, Button\n",
    "    if save:\n",
    "        fig.write_html(file+\"_bar_plot.html\")\n",
    "        fig3.write_html(file+\"_vPCFs.html\")\n",
    "        #fig1.write_html(file+\"_MODEL.html\")\n",
    "        #fig2.write_html(file+\"_EXP.html\")\n",
    "    display(HBox([fig,fig3]))\n",
    "    return vPCFs1, vPCFs2\n",
    "\n",
    "\n",
    "def compare_exp_library_plot(match_DB, target, keys, virtual_dic, atomic_models,exp_img, pixel_size, sigma_threshold = 3, save = False, file= None, model = 'Powell', mark_size=5):\n",
    "    tree_values= match_DB[0]\n",
    "    rotation = match_DB[1]\n",
    "    bs = match_DB[2]\n",
    "    sigma = match_DB[3]\n",
    "    best_match_itree = np.argmin(tree_values)\n",
    "    best_scale_match = bs[best_match_itree]\n",
    "    best_rotation =  rotation[best_match_itree]\n",
    "    best_match_pc = np.array(library_pcs[best_match_itree]) \n",
    "    \n",
    "    sorted_tree_values, sorted_keys, sorted_sigma, sorted_bs, sorted_rotation = zip(*sorted(zip(tree_values, keys, sigma, bs, rotation)))\n",
    "    \n",
    "    #compare the arrays to see differences\n",
    "    differences = np.abs(np.array(sorted_tree_values) - sorted_tree_values[0])\n",
    "    combined_sigma = np.sqrt((sigma_threshold*np.array(sigma))**2 + (sigma_threshold*np.array(sorted_sigma[0]))**2)\n",
    "    within_sigma = differences <= combined_sigma\n",
    "    matches = np.where(within_sigma)[0]\n",
    "    colorbar = ['#1f77b4'] * len(keys)\n",
    "    best_match_tree = []\n",
    "    for index in matches:\n",
    "        colorbar[index] = 'pink'\n",
    "        best_match_tree.append(sorted_keys[index])\n",
    "    \n",
    "    size_exp=min(exp_img.shape)\n",
    "    exp_img=exp_img[0:size_exp,0:size_exp]\n",
    "    # select and crop STEM images\n",
    "    def images_com (rot, index):\n",
    "        rotated_image = rotate(exp_img,-rot*180/np.pi, reshape=False)\n",
    "        crop_size = int(min(exp_img.shape[0], exp_img.shape[1]) / np.sqrt(2))\n",
    "        virtual_pixel = virtual_dic[keys[index]][1]\n",
    "        virtual_size = int(crop_size*pixel_size/virtual_pixel)\n",
    "        virtual = virtual_dic[keys[index]][0]\n",
    "        size_virtual=min(virtual.shape)\n",
    "        virtual=virtual[0:size_virtual,0:size_virtual]\n",
    "        \n",
    "        if virtual.shape[0] < virtual_size:\n",
    "            crop_2 = int(virtual.shape[0]*virtual_pixel/pixel_size)\n",
    "            rotated_image = crop_at_position(rotated_image,crop_2, crop_2, rotated_image.shape[0]//2,rotated_image.shape[1]//2)\n",
    "        else:\n",
    "            rotated_image = crop_at_position(rotated_image,crop_size, crop_size, rotated_image.shape[0]//2,rotated_image.shape[1]//2)\n",
    "            virtual = crop_at_position(virtual,virtual_size, virtual_size, virtual.shape[0]//2,virtual.shape[1]//2)    \n",
    "        model_over = atomic_models[keys[index]]\n",
    "        unique_species = sorted(set(model_over.get_chemical_symbols()))\n",
    "        coord_DB = {}\n",
    "        for atom in unique_species:\n",
    "                coord_DB[atom] = np.array([model_over.positions[i]\n",
    "                                           for i, condition in enumerate(model_over.get_chemical_symbols())\n",
    "                                           if condition==atom])[:,0:2]\n",
    "                coord_DB[atom] = coord_DB[atom][(coord_DB[atom][:,1]/virtual_pixel) < virtual_size//3] / virtual_pixel\n",
    "                coord_DB[atom] = coord_DB[atom][coord_DB[atom][:,0] < virtual_size//3]\n",
    "        \n",
    "        img = hs.signals.Signal2D(virtual)\n",
    "        image_fit = am.get_atom_positions(img, pca=False, separation=7)\n",
    "        sublattices = am.Sublattice(image_fit, image=img.data, fix_negative_values=True)\n",
    "        points = sublattices.atom_positions[:, [1, 0]]\n",
    "        \n",
    "        def objective(translation, points1, points2):\n",
    "            dx, dy = translation  # Translation in x and y\n",
    "            translated_points1 = points1 + np.array([dx, dy])\n",
    "            distances = np.linalg.norm(translated_points1[:, None] - points2, axis=2)\n",
    "            return np.sum(np.min(distances, axis=1))  # Sum of distances to nearest neighbors\n",
    "        # Minimize the objective function\n",
    "        result = minimize(objective, np.array([0, 0]), args=(points, coord_DB['Hf']), method=model)\n",
    "        for key in coord_DB:\n",
    "            coord_DB[key] -= result.x\n",
    "        return rotated_image, virtual,virtual_size, coord_DB\n",
    "    \n",
    "    rotated_image, virtual, virtual_size,coord_DB = images_com (best_rotation, best_match_itree)\n",
    "    #plot\n",
    "    bar1 = go.Bar(\n",
    "        x=sorted_keys,\n",
    "        y=sorted_tree_values,\n",
    "        marker_color = colorbar,\n",
    "        text=[f\"{num:.2f}   \" for num in sorted_bs],         # Text on top of each bar\n",
    "        textposition='outside',  # Position text above bars\n",
    "        textangle=90,\n",
    "        error_y = dict(\n",
    "            type='data',           # Type of error, can also be 'percent' or 'constant'\n",
    "            array=sigma,    # Error values for each bar\n",
    "            #visible=True           # Display the error bars\n",
    "        ),\n",
    "        hovertemplate=(\n",
    "                    '<b>Category:</b> %{x}<br>'  # Displays the x value (Category)\n",
    "                    '<b>Value:</b> %{y}<br>'     # Displays the y value\n",
    "                    '<b>scale:</b> %{text}'  # Displays the error value\n",
    "                    '<extra></extra>'  # Removes the default trace name\n",
    "                )\n",
    "        )\n",
    "    #Plot the Virtual image from the dictionary provided initially showing best match\n",
    "    virtual = go.Heatmap(\n",
    "    z=-virtual,\n",
    "    colorscale=\"Greys\",\n",
    "    showscale=False\n",
    "    )\n",
    "    #Plot all sublattices from the model initially showing best match\n",
    "    fig4 = go.FigureWidget()\n",
    "    # Loop through the data to add scatter plots for each group\n",
    "    for key in coord_DB:\n",
    "        fig4.add_trace(go.Scatter(\n",
    "            x=coord_DB[key][:,1],\n",
    "            y=coord_DB[key][:,0],\n",
    "            mode='markers',  # Use 'markers+lines' for both\n",
    "            name=key,  # Legend entry\n",
    "            marker=dict(\n",
    "            size=5  # Set marker size\n",
    "            )\n",
    "        ))\n",
    "    #Plot experimental STEM image\n",
    "    experiment = go.Heatmap(\n",
    "    z=-rotated_image,\n",
    "    colorscale=\"Greys\",\n",
    "    showscale=False\n",
    "    )\n",
    "    \n",
    "    # vPCF initially showing Experimental data\n",
    "    vPCF1 = go.Scatterpolar(theta=np.mod(xy_to_rt(target)[:,1] + best_rotation,2*np.pi)*180/np.pi,\n",
    "                            r=xy_to_rt(target)[:,0]*best_scale_match,\n",
    "                            mode='markers', \n",
    "                            name='Experimental<br>vPCFs',\n",
    "                            marker=dict(color='blue', size=mark_size))\n",
    "    \n",
    "    # vPCF initially showing best match\n",
    "    vPCF2 = go.Scatterpolar(theta=xy_to_rt(best_match_pc)[:,1]*180/np.pi,\n",
    "                            r=xy_to_rt(best_match_pc)[:,0],\n",
    "                            mode='markers',\n",
    "                            name=\"Best Matches<br>\" + str(best_match_tree),\n",
    "                            marker = dict(color='red', size=mark_size-int(mark_size/2)))\n",
    "    \n",
    "    fig = go.FigureWidget(data=[bar1])\n",
    "    fig1 = go.FigureWidget(data=[virtual])\n",
    "    fig2 = go.FigureWidget(data=[experiment])\n",
    "    fig3 = go.FigureWidget(data=[vPCF1, vPCF2])\n",
    "    for trace in fig4.data:\n",
    "        fig1.add_trace(trace)\n",
    "    \n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        height=400, width=800,\n",
    "        showlegend=False,\n",
    "        title = \"Average Near Neighbor Distance\",\n",
    "        xaxis=dict(tickangle=90),  # Rotate x-axis labels\n",
    "        xaxis2=dict(tickangle=90),\n",
    "        hovermode=\"closest\",\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"left\",\n",
    "            x=0\n",
    "        )\n",
    "    )\n",
    "    fig1.update_layout(\n",
    "        height=400, width=400,\n",
    "        title = \"Simulated Image\",\n",
    "        xaxis=dict(\n",
    "        #range=[0, virtual_size],\n",
    "        tickvals=[],  # No ticks\n",
    "        ticktext=[]   # No tick labels\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "        #range=[0, virtual_size],\n",
    "        tickvals=[],\n",
    "        ticktext=[]\n",
    "        ),\n",
    "        legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"left\",\n",
    "        x=0\n",
    "        )\n",
    "    )\n",
    "    fig2.update_layout(\n",
    "        height=400, width=400,\n",
    "        title = \"Experimental image\",\n",
    "        xaxis=dict(\n",
    "        tickvals=[],  # No ticks\n",
    "        ticktext=[]   # No tick labels\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickvals=[],\n",
    "        ticktext=[]\n",
    "    )\n",
    "    )\n",
    "    \n",
    "    fig3.update_layout(height=400, width=400,\n",
    "                       legend=dict(\n",
    "                                    orientation=\"h\",\n",
    "                                    yanchor=\"bottom\",\n",
    "                                    y=1.02,\n",
    "                                    xanchor=\"left\",\n",
    "                                    x=0\n",
    "                                    ),\n",
    "                        polar=dict(radialaxis=dict(range=[0, limit],\n",
    "                              showline=False,  # Show the radial axis lines\n",
    "                              linewidth=1.5,    # Set the width of the radial axis lines\n",
    "                              linecolor=\"black\",  # Set the color of the radial axis lines\n",
    "                              showticklabels=False,\n",
    "                              showgrid=True,  # Turn on the radial grid\n",
    "                              gridcolor=\"grey\",  # Color of the radial grid\n",
    "                              griddash=\"dot\",  # Style of the radial grid (solid, dot, dash)\n",
    "                              gridwidth=1  # Thickness of the grid line\n",
    "                              ),\n",
    "                              angularaxis=dict(\n",
    "                                      showline=True,  # Show the radial axis lines\n",
    "                                      linewidth=1.5,    # Set the width of the radial axis lines\n",
    "                                      linecolor=\"black\"  # Set the color of the radial axis lines\n",
    "                                      ),\n",
    "                              bgcolor=\"rgba(0,0,0,0)\",# Transparent background for polar plot area\n",
    "                                      ),\n",
    "    )\n",
    "    \n",
    "    def onclick_fn(trace, points, state):\n",
    "        inds = np.array(points.point_inds)\n",
    "        if inds.size:\n",
    "            vPCFs2.name = str(points.xs)\n",
    "            index = keys.index(vPCFs2.name[2:-2])\n",
    "            vPCFs1.r = xy_to_rt(target)[:,0]*bs[index]\n",
    "            vPCFs1.theta = np.mod(xy_to_rt(target)[:,1]+rotation[index],2*np.pi)*180/np.pi\n",
    "            vPCFs2.r = xy_to_rt(library_pcs[index])[:,0]\n",
    "            vPCFs2.theta = xy_to_rt(library_pcs[index])[:,1]*180/np.pi\n",
    "            rotated_image, virtual, virtual_size, coord_DB = images_com (rotation[index], index)\n",
    "            vir.z = - virtual\n",
    "            exp.z = - rotated_image\n",
    "            for i, key in enumerate(coord_DB):\n",
    "                fig1.data[i+1].x = coord_DB[key][:,1]\n",
    "                fig1.data[i+1].y = coord_DB[key][:,0]\n",
    "    \n",
    "    bar1 = fig.data[0]\n",
    "    vir = fig1.data[0]\n",
    "    exp = fig2.data[0]\n",
    "    vPCFs1 = fig3.data[0]\n",
    "    vPCFs2 = fig3.data[1]\n",
    "    bar1.on_click(onclick_fn)\n",
    "    \n",
    "    # ipywidgets\n",
    "    from ipywidgets import HBox, VBox, Button\n",
    "    if save:\n",
    "        fig.write_html(file+\"_bar_plot.html\")\n",
    "        fig3.write_html(file+\"_vPCFs.html\")\n",
    "        fig1.write_html(file+\"_MODEL.html\")\n",
    "        fig2.write_html(file+\"_EXP.html\")\n",
    "    display(HBox([VBox([HBox([fig1, fig2]),fig]),fig3]))\n",
    "    \n",
    "def split_at_x_underscore(s, x = 2):\n",
    "    # Split the string at underscores, with a maximum of 2 splits\n",
    "    parts = s.split('_', x)\n",
    "\n",
    "    # Check if there are at least three parts after splitting\n",
    "    if len(parts) > x:\n",
    "        first_part = '_'.join(parts[:x])\n",
    "        second_part = parts[x]\n",
    "        return first_part, second_part\n",
    "    else:\n",
    "        return s, ''\n",
    "\n",
    "# The two functions in this code block are used to add noise to an image: the first add poisson noise, and the second adds scan-line jitter\n",
    "\n",
    "def add_poisson_noise(img: np.ndarray, px_size: float=0.01, dose: float=1e6) -> np.ndarray:\n",
    "    valmin, valmax = np.min(img), np.max(img)\n",
    "    normed = (img - valmin) / (valmax - valmin)\n",
    "    e_per_px = dose * px_size**2\n",
    "    return np.random.poisson(normed * e_per_px)\n",
    "\n",
    "\n",
    "def add_scan_noise(img: np.ndarray, shift_mag: int=4) -> np.ndarray:\n",
    "    working = img.copy()\n",
    "    for rownum in range(working.shape[0]):\n",
    "        rowshift = np.random.randint(-shift_mag, shift_mag+1)\n",
    "        working[rownum] = np.roll(img[rownum], rowshift)\n",
    "    return working\n",
    "    \n",
    "def parallel_processing(bounds, target, pc, r_limit, nnd='ANND', mask_size=10, **kwargs):\n",
    "\n",
    "    # Single worker function\n",
    "    def process_scale(sc):\n",
    "        scale = sc * 0.001\n",
    "        ANN = near_neighbor_distance(\n",
    "            target, pc,\n",
    "            nnd=nnd,\n",
    "            r_limit=r_limit,\n",
    "            scale=scale,\n",
    "            mask_size=mask_size,\n",
    "            **kwargs\n",
    "        )\n",
    "        # Return the full ANN output + scale (avoid recomputing later)\n",
    "        return ANN, scale\n",
    "\n",
    "    # Create range of scales\n",
    "    scale_values = range(bounds[0], bounds[1] + bounds[2], bounds[2])\n",
    "\n",
    "    # Run in parallel\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(process_scale)(sc) for sc in scale_values\n",
    "    )\n",
    "\n",
    "    return results\n",
    "    \n",
    "def parallel_process_pc(pc, target, bounds, r_limit, nnd='ANND', mask_size=10, **kwargs):\n",
    "\n",
    "    results = parallel_processing(bounds, target, pc, r_limit, nnd, mask_size, **kwargs)\n",
    "\n",
    "    # Extract tree values to find minimum\n",
    "    tree_values = [ANN[1] for ANN, scale in results]\n",
    "\n",
    "    best_idx = np.argmin(tree_values)\n",
    "    best_ANN, best_scale = results[best_idx]\n",
    "\n",
    "    aligned_pc, compared_pc, rotation_value = best_ANN[0]\n",
    "    tree_value = best_ANN[1]\n",
    "    sigma_value = best_ANN[2]\n",
    "\n",
    "    return rotation_value, tree_value, best_scale, sigma_value, aligned_pc, compared_pc\n",
    "\n",
    "def apply_fourier_transform(array, hanning =True):\n",
    "    # Get the dimensions of the input array\n",
    "    a, b, c = array.shape\n",
    "    \n",
    "    if hanning:\n",
    "        window_row = np.hanning(c)[:, np.newaxis]  # Hanning window for rows, reshape to column vector\n",
    "        window_col = np.hanning(b)  # Hanning window for columns\n",
    "        hanning_window_2d = window_row * window_col\n",
    "        \n",
    "        # Perform Fourier transform on dimensions b and c\n",
    "        transformed = np.fft.fft2(array*hanning_window_2d, axes=(1, 2))\n",
    "    else:\n",
    "        transformed = np.fft.fft2(array, axes=(1, 2))\n",
    "\n",
    "    # Calculate the magnitude of the transformed values\n",
    "    magnitude = np.abs(transformed)\n",
    "\n",
    "    # Rearrange the quadrants to shift the zero frequency component to the center\n",
    "    shifted = np.fft.fftshift(magnitude, axes=(1, 2))\n",
    "\n",
    "    # Map the shifted values back to the original array\n",
    "    mapped_array = np.zeros_like(array, dtype=np.float64)\n",
    "    \n",
    "    mapped_array[:, :b, :c] = shifted\n",
    "\n",
    "    return mapped_array\n",
    "    \n",
    "\n",
    "def init_vpcf_h5(filename, image_shape=(1000, 1000)):\n",
    "    \"\"\"\n",
    "    Initialize an HDF5 file for storing vPCF data.\n",
    "    Each frame stores:\n",
    "      - atomic_position: (2,) coordinate\n",
    "      - vpcf_origin: (2,) coordinate\n",
    "      - vpcf_peaks: variable-length (N_peaks, 2)\n",
    "      - vpcf_image: fixed (H, W)\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'w') as f:\n",
    "        grp = f.create_group(\"experiments\")\n",
    "        vlen_float = h5py.vlen_dtype(np.float16)\n",
    "\n",
    "        # Fixed-shape datasets\n",
    "        grp.create_dataset(\n",
    "            \"atomic_positions\", shape=(0, 2),\n",
    "            maxshape=(None, 2), dtype=np.float16\n",
    "        )\n",
    "        grp.create_dataset(\n",
    "            \"vpcf_origin\", shape=(0, 2),\n",
    "            maxshape=(None, 2), dtype=np.float16\n",
    "        )\n",
    "        grp.create_dataset(\n",
    "            \"vpcf_images\", shape=(0, *image_shape),\n",
    "            maxshape=(None, *image_shape), dtype=np.float16\n",
    "        )\n",
    "\n",
    "        # Variable-length peaks (different number of peaks per frame)\n",
    "        grp.create_dataset(\n",
    "            \"vpcf_peaks\", shape=(0,), maxshape=(None,), dtype=vlen_float\n",
    "        )\n",
    "        grp.create_dataset(\n",
    "            \"peaks_shapes\", shape=(0, 2), maxshape=(None, 2), dtype=np.int16\n",
    "        )\n",
    "\n",
    "def append_vpcf_frame(filename, atomic_position, vpcf_origin, vpcf_peaks, vpcf_image):\n",
    "    \"\"\"\n",
    "    Append one vPCF frame (atomic_position, origin, peaks, image) to the HDF5 file.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'a') as f:\n",
    "        grp = f[\"experiments\"]\n",
    "        idx = len(grp[\"atomic_positions\"])\n",
    "\n",
    "        # Resize for the new frame\n",
    "        grp[\"atomic_positions\"].resize((idx + 1, 2))\n",
    "        grp[\"vpcf_origin\"].resize((idx + 1, 2))\n",
    "        grp[\"vpcf_images\"].resize((idx + 1, *grp[\"vpcf_images\"].shape[1:]))\n",
    "        grp[\"vpcf_peaks\"].resize((idx + 1,))\n",
    "        grp[\"peaks_shapes\"].resize((idx + 1, 2))\n",
    "\n",
    "        # Write data\n",
    "        grp[\"atomic_positions\"][idx] = np.array(atomic_position, dtype=np.float16)\n",
    "        grp[\"vpcf_origin\"][idx] = np.array(vpcf_origin, dtype=np.float16)\n",
    "        grp[\"vpcf_images\"][idx] = vpcf_image.astype(np.float16)\n",
    "        grp[\"vpcf_peaks\"][idx] = vpcf_peaks.flatten().astype(np.float16)\n",
    "        grp[\"peaks_shapes\"][idx] = np.array(vpcf_peaks.shape, dtype=np.int16)\n",
    "\n",
    "def read_vpcf_frame(filename, frame_index):\n",
    "    \"\"\"\n",
    "    Read one frame (atomic_position, origin, peaks, image) from the HDF5 file.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        grp = f[\"experiments\"]\n",
    "\n",
    "        atomic_position = grp[\"atomic_positions\"][frame_index]\n",
    "        vpcf_origin = grp[\"vpcf_origin\"][frame_index]\n",
    "\n",
    "        flat_peaks = grp[\"vpcf_peaks\"][frame_index]\n",
    "        peaks_shape = grp[\"peaks_shapes\"][frame_index]\n",
    "        vpcf_peaks = flat_peaks.reshape(peaks_shape)\n",
    "\n",
    "        vpcf_image = grp[\"vpcf_images\"][frame_index]\n",
    "\n",
    "    return atomic_position, vpcf_origin, vpcf_peaks, vpcf_image\n",
    "\n",
    "\n",
    "def initialize_match_results(filename, library_keys):\n",
    "    \"\"\"Initialize the HDF5 file and store library keys once.\"\"\"\n",
    "    with h5py.File(filename, \"w\") as f:\n",
    "        grp_lib = f.create_group(\"library\")\n",
    "        f.create_group(\"columns\")\n",
    "        # Store the library keys once\n",
    "        dt = h5py.string_dtype(encoding=\"utf-8\")\n",
    "        grp_lib.create_dataset(\"keys\", data=np.array(library_keys, dtype=dt))\n",
    "\n",
    "def append_match_results(h5_filename, atomic_position, tree_values, rotation, bs, sigma, library_keys, index):\n",
    "    \"\"\"\n",
    "    Append results for one vPCF frame to the HDF5 file.\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_filename, \"a\") as f:\n",
    "        group_name = f\"columns/atomicposition_{index:06d}\"\n",
    "        grp = f.create_group(group_name)\n",
    "\n",
    "        # Save atomic position (x, y)\n",
    "        grp.create_dataset(\"atomic_position\", data=np.array(atomic_position, dtype=np.float32))\n",
    "\n",
    "        # Save lists of results\n",
    "        grp.create_dataset(\"tree_values\", data=np.array(tree_values, dtype=np.float32))\n",
    "        grp.create_dataset(\"rotation\", data=np.array(rotation, dtype=np.float32))\n",
    "        grp.create_dataset(\"bs\", data=np.array(bs, dtype=np.float32))\n",
    "        grp.create_dataset(\"sigma\", data=np.array(sigma, dtype=np.float32))\n",
    "\n",
    "def read_match_results(filename):\n",
    "    data = {}\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        library_keys = [k.decode(\"utf-8\") for k in f[\"library/keys\"][:]]\n",
    "        for name in f[\"columns\"].keys():\n",
    "            grp = f[\"columns\"][name]\n",
    "            data[name] = {\n",
    "                \"atomic_position\": grp[\"atomic_position\"][:],\n",
    "                \"tree_values\": grp[\"tree_values\"][:],\n",
    "                \"rotation\": grp[\"rotation\"][:],\n",
    "                \"bs\": grp[\"bs\"][:],\n",
    "                \"sigma\": grp[\"sigma\"][:]\n",
    "            }\n",
    "    return library_keys, data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dfa142077916df",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Identify the vPCFs in the membranes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3986f1a7-6ecb-4479-aeb7-678e3bd1a9b8",
   "metadata": {},
   "source": [
    "Let's load an image. You can load the imgaes using any of the library available in python, just make sure the pixel size is in Ã…. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea0a7bb-0622-4ba8-bda9-7c31f5bbdac2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T22:28:15.525756600Z",
     "start_time": "2024-11-20T22:27:56.097285600Z"
    }
   },
   "outputs": [],
   "source": [
    "import SingleOrigin as so\n",
    "\n",
    "#img_path = str(Path.cwd()/\"img/Exp_HZO_R3_HAADF.dm3\")\n",
    "\n",
    "# Uncomment and run this line instead of the above if you want to load your own image:\n",
    "img_path = select_files()[0]\n",
    "\n",
    "image = so.load_image(\n",
    "    path = img_path, \n",
    "    display_image = True,\n",
    "    return_path = True,\n",
    "    images_from_stack = 'all'\n",
    ")\n",
    "\n",
    "#Make sure that the pixel size is in Angstroms  \n",
    "pixel_size = image[1]['pixelSize'][0]*10\n",
    "image=image[0].astype(np.float16)#[0:292,0:292]\n",
    "\n",
    "#image = add_poisson_noise(image, px_size=0.01, dose=1e4)\n",
    "#image = add_scan_noise(image, shift_mag=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e48497-b9a6-460a-8935-865548fe0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = hs.signals.Signal2D(image)\n",
    "image_fit = am.get_atom_positions(img, pca=True, separation=5)\n",
    "sublattices = am.Sublattice(image_fit, image=img.data)\n",
    "sublattices.find_nearest_neighbors()\n",
    "sublattices.refine_atom_positions_using_center_of_mass(show_progressbar=True)\n",
    "sublattices.refine_atom_positions_using_2d_gaussian(show_progressbar=True)\n",
    "coords = sublattices.atom_positions * pixel_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6091ec-e838-4355-8295-8977c01305be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sublattices.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56a77db-302d-4268-84b2-b7585a192212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import atomai as aoi\n",
    "window_size = 128 #min 64 to get 6 atomic columns in image\n",
    "step_size = int(window_size/2)\n",
    "\n",
    "coordinates = aoi.utils.get_coord_grid(image, step_size)\n",
    "coords = coordinates[0]\n",
    "imstack_grid_nio, com_grid_nio, frames_grid_nio = aoi.utils.extract_subimages(image, coordinates, window_size)\n",
    "imstack_grid_nio = np.squeeze(imstack_grid_nio, axis = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47aa1b-dfea-400b-87bf-97179cc71809",
   "metadata": {},
   "outputs": [],
   "source": [
    "imstack_grid_nio_fft = apply_fourier_transform(imstack_grid_nio, hanning = True)\n",
    "imstack_grid_nio_fft.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f2827e-dc6f-4ae2-b213-1ed8bd9d75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imstack_analysis = imstack_grid_nio_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e2628d-8d54-48be-b3e7-7739f58f699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)   # fix seed so that we get the same samples displayed at every run\n",
    "\n",
    "fig, axes = plt.subplots(8, 8, figsize=(8, 8),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "for ax in axes.flat:\n",
    "    i = np.random.randint(len(imstack_analysis))\n",
    "    ax.imshow(np.log(imstack_analysis[i,...]), cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0087bcdf-85f3-424e-9eaf-526ac56e1d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nio = imstack_analysis[...].reshape([-1, window_size*window_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b8be70-919a-4b54-9e7b-c744cbb9bf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "nc=4\n",
    "clusters = KMeans(n_clusters=nc, random_state=0).fit(X_nio)\n",
    "nio_centers = clusters.cluster_centers_\n",
    "nio_labels = clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2dadfe-d706-44a9-b4e0-6671f15d8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "rows, cols = 3, 6\n",
    "gs2 = gridspec.GridSpec(rows, cols)\n",
    "\n",
    "fig2 = plt.figure(figsize = (4*cols, 4*(1+rows//1.5)))\n",
    "\n",
    "for i in range(nc):\n",
    "    ax2 = fig2.add_subplot(gs2[i])\n",
    "    ax2.imshow(nio_centers[i,:].reshape(window_size, window_size)**(1), cmap = 'inferno', origin = 'lower')\n",
    "    ax2.set_title('Component ' + str(i))\n",
    "    plt.tick_params(labelsize = 18)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9245abb-833c-4da7-b32a-bf6237e204cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(resize(image, (int(image.shape[0]/step_size)-1,int(image.shape[1]/step_size)))-1, cmap='gray')\n",
    "z_img = nio_labels.reshape(int(image.shape[0]/step_size)-1,int(image.shape[1]/step_size)-1)\n",
    "plt.imshow(z_img,  cmap = 'jet', alpha=0.5)\n",
    "#plt.colorbar()\n",
    "#plt.gca().invert_yaxis()\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be34ac56-0d23-44d3-a8fd-de752d2c8213",
   "metadata": {},
   "source": [
    "# Locate the atomic columns and generate the vPCF for the entire image\n",
    "\n",
    "In this section, the linearKDE_2D_float16 is used to modify in the script the so_utils.linearKDE_2D function from a single origin to reduce the size of the data using float32. If your image is not very large, that function can be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ad18a-e0c2-4b47-a25f-1d3ba6f54481",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use this code if the float64 is creating memory issues in SingleOrigin\n",
    "import SingleOrigin.utils as so_utils\n",
    "import numpy as np\n",
    "\n",
    "# orig_linearKDE_2D = so_utils.linearKDE_2D\n",
    "\n",
    "# def linearKDE_2D_float16(*args, **kwargs):\n",
    "#     out = orig_linearKDE_2D(*args, **kwargs)\n",
    "#     if isinstance(out, tuple):\n",
    "#         return tuple(o.astype(np.float16) if isinstance(o, np.ndarray) else o for o in out)\n",
    "#     elif isinstance(out, np.ndarray):\n",
    "#         return out.astype(np.float16)\n",
    "#     else:\n",
    "#         return out\n",
    "\n",
    "# so_utils.linearKDE_2D = linearKDE_2D_float16\n",
    "\n",
    "\n",
    "######################################\n",
    "exp_vPCF = create_vpcfs_images((image,pixel_size), fit_atom_gaussian=True, method = 'gauss', blur_vpcf=2, separation=5, show_progressbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be6aa11-fd51-4925-8d05-453d0a6efdf4",
   "metadata": {},
   "source": [
    "Make sure you visualize the atomic column fitting by extracting the atomap lattice and plot the vPCF to make sure the peaks are correctly identify. You can modify the parameter (e.g. separation) to improve the fitting. Note that a few false positive or false negative atomic columns do not significantly affect the final result. Save the cartesian vPCF in a different variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951404be-8cd4-4d2d-975f-c26a8863c53c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T22:28:16.069214200Z",
     "start_time": "2024-11-20T22:28:15.538756500Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "exp_vpcf = exp_vPCF[1]\n",
    "\n",
    "# Create the GridSpec layout\n",
    "fig = plt.figure(figsize=(10, 5))  # Set a suitable figure size\n",
    "gs = GridSpec(1, 2, width_ratios=[1, 1], figure=fig)  # Create a 1-row, 2-column layout\n",
    "\n",
    "# gaussina plot\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax1.scatter(exp_vPCF[2].x_position, exp_vPCF[2].y_position, c='red', s=2, alpha = 0.5)\n",
    "ax1.imshow(-image, cmap ='Greys')\n",
    "ax1.set_axis_off() \n",
    "ax1.set_title(\"2D Gaussian Fitting\")\n",
    "\n",
    "# vPCF plot\n",
    "ax2 = fig.add_subplot(gs[1])\n",
    "ax2.scatter(exp_vPCF[1][:,1]+exp_vPCF[0][1][1], exp_vPCF[1][:,0]+exp_vPCF[0][1][0], marker = 'o', s=20, edgecolor='orange', facecolor ='none', linewidth=1, alpha = 0.5)\n",
    "im = ax2.imshow(-exp_vPCF[0][0], cmap ='Greys')\n",
    "ax2.set_axis_off()\n",
    "ax2.set_title(\"vPCF\")\n",
    "#plt.savefig(Path(img_path[0]).stem+'Gaussian_fitting_vPCF.png', dpi=300) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab0074-a446-4b95-bd92-0184294b2701",
   "metadata": {},
   "source": [
    "## Matching experimental vPCFs\n",
    "Let's now match our vPCF to the library we created in previous steps. If you did not create the library in previous steps you can simply load one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb4ee47-5256-442d-8be5-dc0327174ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vpcffit.vpcffit import create_vpcfs_images\n",
    "cluster_blur_vpcf, origin = exp_vPCF[0]\n",
    "cluster_exp_vpcf = exp_vPCF[1]\n",
    "cluster_lattice = exp_vPCF[2]\n",
    "cluster_lattice.plot(markersize = 0.4, title='', colorbar=None, axes_off = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f5a348-3e91-4b81-9a80-fc40895aa269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ERRASE\n",
    "from vpcffit.vpcffit import create_vpcfs_images\n",
    "cluster_lattice = sublattices\n",
    "#cluster_lattice.plot(markersize = 0.4, title='', colorbar=None, axes_off = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b091df0-c9dc-449c-b50e-ebf12f86d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vpcffit.vpcffit import crop_at_position\n",
    "imstack_single = []\n",
    "coor_single = []\n",
    "coordinates_around_point = []\n",
    "window_size = 100\n",
    "coord = np.round(cluster_lattice.atom_positions).astype(int)\n",
    "for value in tqdm(coord):\n",
    "    im = crop_at_position(image,window_size,window_size,value[0], value[1])\n",
    "    # if im.shape == (window_size, window_size):\n",
    "    imstack_single.append(im) \n",
    "    given_point = [value[0], value[1]]\n",
    "    x_comp = (cluster_lattice.atom_positions[:,1] - given_point[1])\n",
    "    y_comp = (cluster_lattice.atom_positions[:,0]  - given_point[0])\n",
    "    distances = ((cluster_lattice.atom_positions[:,1] - given_point[1])**2 + (cluster_lattice.atom_positions[:,0]  - given_point[0])**2)**0.5\n",
    "    indices = np.where(distances <= window_size)[0]\n",
    "    coordinates_around_point.append(cluster_lattice.atom_positions[indices])\n",
    "    coor_single.append(given_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5696e546-da21-4132-b2ca-1b1dc537a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ind = np.random.randint(0, len(imstack_single))\n",
    "points = np.array(coordinates_around_point[ind])\n",
    "#ax.scatter(np.array(coor_single)[:,0],np.array(coor_single)[:,1], c='yellow',s=1)\n",
    "ax.scatter(points[:,0],points[:,1], c='red',s=1)\n",
    "ax.scatter(coor_single[ind][0],coor_single[ind][1], c='blue',s=5)\n",
    "ax.imshow(-image, cmap='Grays')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e8798b-86ac-431b-a495-4239f5f2a25e",
   "metadata": {},
   "source": [
    "The process of generating vPCF and locating its peaks for each atomic position takes a long time, and hence, it is better to save the data while it is creating them. The data will be saved in frames each frame, each of them corresponds to a single atomic column position. In the next cell we create the functions to save and read the data in h5 files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633f0e98-0fc7-4beb-9844-0ab7b0df9578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def init_vpcf_h5(filename, image_shape=(1000, 1000)):\n",
    "    \"\"\"\n",
    "    Initialize an HDF5 file for storing vPCF data.\n",
    "    Each frame stores:\n",
    "      - atomic_position: (2,) coordinate\n",
    "      - vpcf_origin: (2,) coordinate\n",
    "      - vpcf_peaks: variable-length (N_peaks, 2)\n",
    "      - vpcf_image: fixed (H, W)\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'w') as f:\n",
    "        grp = f.create_group(\"experiments\")\n",
    "        vlen_float = h5py.vlen_dtype(np.float16)\n",
    "\n",
    "        # Fixed-shape datasets\n",
    "        grp.create_dataset(\n",
    "            \"atomic_positions\", shape=(0, 2),\n",
    "            maxshape=(None, 2), dtype=np.float16\n",
    "        )\n",
    "        grp.create_dataset(\n",
    "            \"vpcf_origin\", shape=(0, 2),\n",
    "            maxshape=(None, 2), dtype=np.float16\n",
    "        )\n",
    "        grp.create_dataset(\n",
    "            \"vpcf_images\", shape=(0, *image_shape),\n",
    "            maxshape=(None, *image_shape), dtype=np.float16\n",
    "        )\n",
    "\n",
    "        # Variable-length peaks (different number of peaks per frame)\n",
    "        grp.create_dataset(\n",
    "            \"vpcf_peaks\", shape=(0,), maxshape=(None,), dtype=vlen_float\n",
    "        )\n",
    "        grp.create_dataset(\n",
    "            \"peaks_shapes\", shape=(0, 2), maxshape=(None, 2), dtype=np.int16\n",
    "        )\n",
    "\n",
    "def append_vpcf_frame(filename, atomic_position, vpcf_origin, vpcf_peaks, vpcf_image):\n",
    "    \"\"\"\n",
    "    Append one vPCF frame (atomic_position, origin, peaks, image) to the HDF5 file.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'a') as f:\n",
    "        grp = f[\"experiments\"]\n",
    "        idx = len(grp[\"atomic_positions\"])\n",
    "\n",
    "        # Resize for the new frame\n",
    "        grp[\"atomic_positions\"].resize((idx + 1, 2))\n",
    "        grp[\"vpcf_origin\"].resize((idx + 1, 2))\n",
    "        grp[\"vpcf_images\"].resize((idx + 1, *grp[\"vpcf_images\"].shape[1:]))\n",
    "        grp[\"vpcf_peaks\"].resize((idx + 1,))\n",
    "        grp[\"peaks_shapes\"].resize((idx + 1, 2))\n",
    "\n",
    "        # Write data\n",
    "        grp[\"atomic_positions\"][idx] = np.array(atomic_position, dtype=np.float16)\n",
    "        grp[\"vpcf_origin\"][idx] = np.array(vpcf_origin, dtype=np.float16)\n",
    "        grp[\"vpcf_images\"][idx] = vpcf_image.astype(np.float16)\n",
    "        grp[\"vpcf_peaks\"][idx] = vpcf_peaks.flatten().astype(np.float16)\n",
    "        grp[\"peaks_shapes\"][idx] = np.array(vpcf_peaks.shape, dtype=np.int16)\n",
    "\n",
    "def read_vpcf_frame(filename, frame_index):\n",
    "    \"\"\"\n",
    "    Read one frame (atomic_position, origin, peaks, image) from the HDF5 file.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        grp = f[\"experiments\"]\n",
    "\n",
    "        atomic_position = grp[\"atomic_positions\"][frame_index]\n",
    "        vpcf_origin = grp[\"vpcf_origin\"][frame_index]\n",
    "\n",
    "        flat_peaks = grp[\"vpcf_peaks\"][frame_index]\n",
    "        peaks_shape = grp[\"peaks_shapes\"][frame_index]\n",
    "        vpcf_peaks = flat_peaks.reshape(peaks_shape)\n",
    "\n",
    "        vpcf_image = grp[\"vpcf_images\"][frame_index]\n",
    "\n",
    "    return atomic_position, vpcf_origin, vpcf_peaks, vpcf_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a08f0a-5af2-45b7-95e6-7411423487c9",
   "metadata": {},
   "source": [
    "Now let's extract the vPCF at each atomic column position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9404b63-6b31-4969-837b-f094356fed3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "from IPython.display import clear_output\n",
    "from vpcffit.vpcffit import extract_peak_coords\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "plot = False\n",
    "init_vpcf_h5(Path(img_path).stem+'_100pixels.h5', image_shape=(999, 999))\n",
    "\n",
    "if plot:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "for i in tqdm(range(len(coordinates_around_point))):\n",
    "    vpcf, orig = so.get_vpcf(\n",
    "                  xlim = [-10, 10],\n",
    "                  ylim = [-10, 10],\n",
    "                  coords1 = coordinates_around_point [i]*pixel_size,\n",
    "                  d = 0.02,\n",
    "                  )\n",
    "    blur_vpcf = gaussian_filter(vpcf.astype('float32'), sigma = 3)\n",
    "    vpcf_peaks = extract_peak_coords(orig, blur_vpcf, method = 'gauss')\n",
    "    append_vpcf_frame(Path(img_path).stem+'_100pixels.h5', np.array(coor_single[i]), orig, vpcf_peaks, blur_vpcf)\n",
    "    \n",
    "    #PLOTS AND UPDATE THE VPCFS AND THE PEAKS TO VERIFY PROPER FITTING\n",
    "    if plot:\n",
    "        ax.clear()\n",
    "        ax.imshow(np.array(blur_vpcf), cmap='grey')\n",
    "        ax.scatter(vpcf_peaks[:, 1]+orig[1], vpcf_peaks[:,0]+orig[1], c='r', alpha = 0.3, s=2, label='DataBase')\n",
    "        clear_output(wait=True)\n",
    "        display(fig)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ab8a6-b911-4ed5-a679-1f9c63c58af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##FUNCTION\n",
    "def read_vpcf_frame(filename, frame_index):\n",
    "    \"\"\"\n",
    "    Read one frame (atomic_position, origin, peaks, image) from the HDF5 file.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        grp = f[\"experiments\"]\n",
    "\n",
    "        atomic_position = grp[\"atomic_positions\"][frame_index]\n",
    "        vpcf_origin = grp[\"vpcf_origin\"][frame_index]\n",
    "\n",
    "        flat_peaks = grp[\"vpcf_peaks\"][frame_index]\n",
    "        peaks_shape = grp[\"peaks_shapes\"][frame_index]\n",
    "        vpcf_peaks = flat_peaks.reshape(peaks_shape)\n",
    "\n",
    "        vpcf_image = grp[\"vpcf_images\"][frame_index]\n",
    "\n",
    "    return atomic_position, vpcf_origin, vpcf_peaks, vpcf_image\n",
    "\n",
    "# ##Implementation\n",
    "# atomic_positions2 = []\n",
    "# vpcf_origin2 = []\n",
    "# vpcf_peaks2 = []\n",
    "# vpcf_image2 = []\n",
    "# for i in tqdm(range(11505)):\n",
    "#     atomic_position, vpcf_origin, vpcf_peaks, vpcf_image = read_vpcf_frame(Path(img_path).stem+'.h5', i)\n",
    "#     atomic_positions2.append(atomic_position)\n",
    "#     vpcf_origin2.append(vpcf_origin)\n",
    "#     vpcf_peaks2.append(vpcf_peaks)\n",
    "#     vpcf_image2.append(vpcf_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58ddbd0-2e72-4daf-9f6c-7b876b618b47",
   "metadata": {},
   "source": [
    "The next cell allows you to read a h5 file with the information of the atomic position, vPCF (including the origin) and the vPCF peaks, extracted in the previous cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d1cc1-445c-4c7a-9136-b388b0045b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_positions2 = []\n",
    "vpcf_origin2 = []\n",
    "vpcf_peaks2 = []\n",
    "vpcf_image2 = []\n",
    "for i in tqdm(range(13402)):\n",
    "    atomic_position, vpcf_origin, vpcf_peaks, vpcf_image = read_vpcf_frame(Path(img_path).stem+'_100pixels.h5', i)\n",
    "    atomic_positions2.append(atomic_position)\n",
    "    vpcf_origin2.append(vpcf_origin)\n",
    "    vpcf_peaks2.append(vpcf_peaks)\n",
    "    vpcf_image2.append(vpcf_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3125333-a1ab-436a-a950-7d8c453218a4",
   "metadata": {},
   "source": [
    "Now we can plot one of the vPCF and the corresponding peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c21e9f6-4412-437e-8d02-e985ef5a5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 10\n",
    "plt.imshow(vpcf_image2[index])\n",
    "plt.scatter(vpcf_peaks2[index][:, 1]+vpcf_origin2[index][1], vpcf_peaks2[index][:,0]+vpcf_origin2[index][1], c='white', alpha = 1, s=2, label='DataBase')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd27274-a380-4d07-b8d8-f957d9b1578d",
   "metadata": {},
   "source": [
    "### Clustering the data to reduce dimensionality\n",
    "\n",
    "The vPCFs calculated at each atomic column are clustered using a miniBatchKmeans algorithm to reduce the data dimensionality and run the vPCF match algorithm only on the clusters. This results in a much faster process that matches individual vPCF for each atomic column. \n",
    "This clustering algorithm requires defining the number of clusters in advance and thus, a large number of clusters would be recommended (e.g., 20), since the vPCF matching procedure can further reduce the number of regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0647804c-bad6-4b1a-810f-9615f8e43f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=80,\n",
    "    metric='cosine'\n",
    ")\n",
    "flat_vPCF = np.array(vpcf_image2).reshape([-1, 999*999])\n",
    "labels = clusterer.fit_predict(flat_vPCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a705f7-8c22-4e66-ab72-a1799f5fb604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "batch_size = 512\n",
    "\n",
    "mbk = MiniBatchKMeans(n_clusters=10, batch_size=batch_size, random_state=0)\n",
    "\n",
    "for batch_start in range(0, len(vpcf_image2), batch_size):\n",
    "    batch_end = min(batch_start + batch_size, len(vpcf_image2))\n",
    "    X_batch = np.array(vpcf_image2[batch_start:batch_end]).reshape(batch_end-batch_start, -1)\n",
    "    mbk.partial_fit(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edacbb1-7f9d-49fd-afb6-ee3f704402aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = np.zeros(len(vpcf_image2), dtype=int)\n",
    "for batch_start in range(0, len(vpcf_image2), batch_size):\n",
    "    batch_end = min(batch_start + batch_size, len(vpcf_image2))\n",
    "    X_batch = np.array([img.ravel() for img in vpcf_image2[batch_start:batch_end]])\n",
    "    all_labels[batch_start:batch_end] = mbk.predict(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab3f309-ca27-4375-9821-1fe0bba8e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_clusters = mbk.cluster_centers_.reshape(-1, 999, 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a21d696-29f9-482c-85f3-6d53541ff0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "n_clusters = mbk.n_clusters\n",
    "cmap = plt.get_cmap('tab20', n_clusters)  # discrete colormap with n_clusters\n",
    "norm = mpl.colors.BoundaryNorm(np.arange(n_clusters+1)-0.5, n_clusters)\n",
    "\n",
    "# Assign colors to each label\n",
    "colors = [cmap(i) for i in all_labels]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot the image\n",
    "ax.imshow(image, cmap='gray', origin='lower')\n",
    "\n",
    "# Overlay scatter\n",
    "ax.scatter(\n",
    "    np.array(atomic_positions2)[:, 0],\n",
    "    np.array(atomic_positions2)[:, 1],\n",
    "    c=colors,\n",
    "    s=5\n",
    ")\n",
    "ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fde5ae-6630-4b27-9e20-5f370d8aac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "rows, cols = 2, 5\n",
    "gs2 = gridspec.GridSpec(rows, cols)\n",
    "\n",
    "fig2 = plt.figure(figsize = (4*cols, 4*(1+rows//1.5)))\n",
    "\n",
    "for i in range(mbk.n_clusters):\n",
    "    ax2 = fig2.add_subplot(gs2[i])\n",
    "    ax2.imshow(centers_clusters[i,:], cmap = 'inferno', origin = 'lower', vmax = 20)\n",
    "    ax2.set_title('Component ' + str(i))\n",
    "    plt.tick_params(labelsize = 18)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772dde4b-2c50-4d7e-97a4-4b7177815b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "vpcfs_clustered =  centers_clusters\n",
    "vpcf_peaks_list_clusters = []\n",
    "for vpcf in tqdm(vpcfs_clustered):\n",
    "    orig = [np.array(vpcf).shape[0]/2,np.array(vpcf).shape[1]/2]\n",
    "    blur_vpcf = gaussian_filter(vpcf, sigma = 1)\n",
    "    vpcf_peaks = extract_peak_coords(orig,np.array(blur_vpcf), min_dist = 8)\n",
    "    vpcf_peaks_list_clusters.append(vpcf_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275101da-c241-44a1-8b77-7011eb76010c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
